[[metrics]]
== Hadoop Metrics

The Hadoop system records a set of metric counters for each job that it runs. {eh} extends on that and provides metrics about its activity for each job run by leveraging the Hadoop infrastructure. http://hadoop.apache.org/docs/r2.2.0/api/org/apache/hadoop/mapred/Counters.html[Counters] infrastructure. During each run, {eh} sends statistics from each task instance, as it is running, which get aggregated by the {mr} infrastructure and are available through the standard Hadoop APIs.

{eh} provides the following counters, available under `org.elasticsearch.hadoop.mr.Counter` enum:

.Available counters
[cols="^,^",options="header"]

|===
| Counter name | Purpose

2+h| Data focused

| BYTES_WRITTEN | Total number of data/communication written over the network in bytes
| BYTES_ACCEPTED | Data/Documents accepted by {es} in bytes 
| BYTES_RETRIED | Data/Documents rejected by {es} in bytes 
| BYTES_READ | Data/Documents read by {es} in bytes 

2+h| Document focused

| DOCS_WRITTEN | Number of docs written/sent over the network 
| DOCS_ACCEPTED | Number of documents sent and accepted by {es} 
| DOCS_RETRIED | Number of documents sent but rejected by {es} 
| DOCS_READ | Number of documents read from {es} 

2+h| Network focused

| BULK_WRITES  | Number of bulk requests made 
| BULK_RETRIES | Number of bulk retries (caused by document rejections) 
| SCROLL_READS | Number of scroll reads 
| NODE_RETRIES | Number of node fall backs (caused by network errors) 
| NET_RETRIES  | Number of network retries (caused by network errors) 

2+h| Time focused

| NET_TOTAL_TIME_MS | Overall time (in ms) spent over the network 
| BULK_TOTAL_TIME_MS | Time (in ms) spent over the network by the bulk requests 
| BULK_RETRIES_TOTAL_TIME_MS | Time (in ms) spent over the network retrying bulk requests 
| SCROLL_TOTAL_TIME_MS | Time (in ms) spent over the network reading the scroll requests 

|===

One can the counters programatically, depending on the API used, http://hadoop.apache.org/docs/r2.2.0/api/index.html?org/apache/hadoop/mapred/Counters.html[mapred] or http://hadoop.apache.org/docs/r2.2.0/api/index.html?org/apache/hadoop/mapreduce/Counter.html[mapreduce]. Whatever the choice, {eh} performs automatic reports without any user intervention. In fact, when using {eh} one will see the stats reported at the end of the job run, for example:

[source, bash]
----
13:55:08,100  INFO main mapreduce.Job - Job job_local127738678_0013 completed successfully
13:55:08,101  INFO main mapreduce.Job - Counters: 35
...
Elasticsearch Hadoop Counters
    Bulk Retries=0
    Bulk Retries Total Time(ms)=0
    Bulk Total Time(ms)=518
    Bulk Writes=20
    Bytes Accepted=159129
    Bytes Read=79921
    Bytes Retried=0
    Bytes Written=159129
    Documents Accepted=993
    Documents Read=0
    Documents Retried=0
    Documents Written=993
    Network Retries=0
    Network Total Time(ms)=937
    Node Retries=0
    Scroll Reads=0
    Scroll Total Time(ms)=0

----
